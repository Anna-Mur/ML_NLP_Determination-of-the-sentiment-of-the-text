{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Определение тональности текста\n",
    "\n",
    "__Задача:__ обучить модель (бинарной классификации) распознавать тональность текста (негативная и позитивная).\n",
    "\n",
    "Набор данных взят с сайта https://study.mokoron.com/ и представляет собой набор из 114911 положительных, 111923 отрицательных записей из русскоязычного твиттера."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание столбцов\n",
    "\n",
    "– id: уникальный номер сообщения в системе twitter;\n",
    "\n",
    "– tdate: дата публикации сообщения (твита);\n",
    "\n",
    "– tmane: имя пользователя, опубликовавшего сообщение;\n",
    "\n",
    "– ttext: текст сообщения (твита);\n",
    "\n",
    "– ttype: класс, к которому принадлежит текст (положительный, отрицательный, нейтральный);\n",
    "\n",
    "– tret: количество ретвитов (количество копирований этого сообщения другими пользователями);\n",
    "\n",
    "– trep: количество реплаев к данному сообщению. В настоящий момент API твиттера не отдает эту информацию;\n",
    "\n",
    "– tfav: число сколько раз данное сообщение было добавлено в избранное другими пользователями;\n",
    "\n",
    "– tstcount: число всех сообщений пользователя в сети twitter;\n",
    "\n",
    "– tfol: количество фоловеров пользователя (тех людей, которые читают пользователя);\n",
    "\n",
    "– tfrien: количество друзей пользователя (те люди, которых читает пользователь);\n",
    "\n",
    "– listcount: количество листов-подписок в которые добавлен твиттер-пользователь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anna.muravyeva\\Anaconda3\\envs\\NewEnvPython37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Anna.muravyeva\\Anaconda3\\envs\\NewEnvPython37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Anna.muravyeva\\Anaconda3\\envs\\NewEnvPython37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Anna.muravyeva\\Anaconda3\\envs\\NewEnvPython37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Anna.muravyeva\\Anaconda3\\envs\\NewEnvPython37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Anna.muravyeva\\Anaconda3\\envs\\NewEnvPython37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Anna.muravyeva\\Anaconda3\\envs\\NewEnvPython37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Anna.muravyeva\\Anaconda3\\envs\\NewEnvPython37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Anna.muravyeva\\Anaconda3\\envs\\NewEnvPython37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Anna.muravyeva\\Anaconda3\\envs\\NewEnvPython37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Anna.muravyeva\\Anaconda3\\envs\\NewEnvPython37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Anna.muravyeva\\Anaconda3\\envs\\NewEnvPython37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tensorflow as ts\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Embedding, Activation, Flatten, Dense, Conv1D, MaxPooling1D, Dropout\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных/ создание датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames=['id', 'tdate', 'tmane', 'ttext', 'ttype', 'tret', 'trep', 'tfav', 'tstcount', 'tfol', 'tfrien', 'listcount']\n",
    "positive_df = pd.read_csv('positive.csv', sep=';', names=colnames, header=None, error_bad_lines=False)\n",
    "negative_df = pd.read_csv('negative.csv', sep=';', names=colnames, header=None, error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tdate</th>\n",
       "      <th>tmane</th>\n",
       "      <th>ttext</th>\n",
       "      <th>ttype</th>\n",
       "      <th>tret</th>\n",
       "      <th>trep</th>\n",
       "      <th>tfav</th>\n",
       "      <th>tstcount</th>\n",
       "      <th>tfol</th>\n",
       "      <th>tfrien</th>\n",
       "      <th>listcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>408906762813579264</td>\n",
       "      <td>1386325944</td>\n",
       "      <td>dugarchikbellko</td>\n",
       "      <td>на работе был полный пиддес :| и так каждое за...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8064</td>\n",
       "      <td>111</td>\n",
       "      <td>94</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>408906818262687744</td>\n",
       "      <td>1386325957</td>\n",
       "      <td>nugemycejela</td>\n",
       "      <td>Коллеги сидят рубятся в Urban terror, а я из-з...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>42</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>408906858515398656</td>\n",
       "      <td>1386325966</td>\n",
       "      <td>4post21</td>\n",
       "      <td>@elina_4post как говорят обещаного три года жд...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>718</td>\n",
       "      <td>49</td>\n",
       "      <td>249</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>408906914437685248</td>\n",
       "      <td>1386325980</td>\n",
       "      <td>Poliwake</td>\n",
       "      <td>Желаю хорошего полёта и удачной посадки,я буду...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10628</td>\n",
       "      <td>207</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>408906914723295232</td>\n",
       "      <td>1386325980</td>\n",
       "      <td>capyvixowe</td>\n",
       "      <td>Обновил за каким-то лешим surf, теперь не рабо...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>17</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111918</th>\n",
       "      <td>425138243257253888</td>\n",
       "      <td>1390195830</td>\n",
       "      <td>Yanch_96</td>\n",
       "      <td>Но не каждый хочет что то исправлять:( http://...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1138</td>\n",
       "      <td>32</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111919</th>\n",
       "      <td>425138339503943682</td>\n",
       "      <td>1390195853</td>\n",
       "      <td>tkit_on</td>\n",
       "      <td>скучаю так :-( только @taaannyaaa вправляет мо...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4822</td>\n",
       "      <td>38</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111920</th>\n",
       "      <td>425138437684215808</td>\n",
       "      <td>1390195876</td>\n",
       "      <td>ckooker1</td>\n",
       "      <td>Вот и в школу, в говно это идти уже надо(</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111921</th>\n",
       "      <td>425138490452344832</td>\n",
       "      <td>1390195889</td>\n",
       "      <td>LisaBeroud</td>\n",
       "      <td>RT @_Them__: @LisaBeroud Тауриэль, не грусти :...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2516</td>\n",
       "      <td>187</td>\n",
       "      <td>265</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111922</th>\n",
       "      <td>425138595251625984</td>\n",
       "      <td>1390195914</td>\n",
       "      <td>sukapavlov</td>\n",
       "      <td>Такси везет меня на работу. Раздумываю приплат...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7778</td>\n",
       "      <td>146</td>\n",
       "      <td>66</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111923 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id       tdate            tmane  \\\n",
       "0       408906762813579264  1386325944  dugarchikbellko   \n",
       "1       408906818262687744  1386325957     nugemycejela   \n",
       "2       408906858515398656  1386325966          4post21   \n",
       "3       408906914437685248  1386325980         Poliwake   \n",
       "4       408906914723295232  1386325980       capyvixowe   \n",
       "...                    ...         ...              ...   \n",
       "111918  425138243257253888  1390195830         Yanch_96   \n",
       "111919  425138339503943682  1390195853          tkit_on   \n",
       "111920  425138437684215808  1390195876         ckooker1   \n",
       "111921  425138490452344832  1390195889       LisaBeroud   \n",
       "111922  425138595251625984  1390195914       sukapavlov   \n",
       "\n",
       "                                                    ttext  ttype  tret  trep  \\\n",
       "0       на работе был полный пиддес :| и так каждое за...     -1     0     0   \n",
       "1       Коллеги сидят рубятся в Urban terror, а я из-з...     -1     0     0   \n",
       "2       @elina_4post как говорят обещаного три года жд...     -1     0     0   \n",
       "3       Желаю хорошего полёта и удачной посадки,я буду...     -1     0     0   \n",
       "4       Обновил за каким-то лешим surf, теперь не рабо...     -1     0     0   \n",
       "...                                                   ...    ...   ...   ...   \n",
       "111918  Но не каждый хочет что то исправлять:( http://...     -1     0     0   \n",
       "111919  скучаю так :-( только @taaannyaaa вправляет мо...     -1     0     0   \n",
       "111920          Вот и в школу, в говно это идти уже надо(     -1     0     0   \n",
       "111921  RT @_Them__: @LisaBeroud Тауриэль, не грусти :...     -1     0     1   \n",
       "111922  Такси везет меня на работу. Раздумываю приплат...     -1     0     0   \n",
       "\n",
       "        tfav  tstcount  tfol  tfrien  listcount  \n",
       "0          0      8064   111      94          2  \n",
       "1          0        26    42      39          0  \n",
       "2          0       718    49     249          0  \n",
       "3          0     10628   207     200          0  \n",
       "4          0        35    17      34          0  \n",
       "...      ...       ...   ...     ...        ...  \n",
       "111918     0      1138    32      46          0  \n",
       "111919     0      4822    38      32          0  \n",
       "111920     1       165    13      16          0  \n",
       "111921     0      2516   187     265          0  \n",
       "111922     0      7778   146      66          5  \n",
       "\n",
       "[111923 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         @first_timee хоть я и школота, но поверь, у на...\n",
       "1         Да, все-таки он немного похож на него. Но мой ...\n",
       "2         RT @KatiaCheh: Ну ты идиотка) я испугалась за ...\n",
       "3         RT @digger2912: \"Кто то в углу сидит и погибае...\n",
       "4         @irina_dyshkant Вот что значит страшилка :D\\nН...\n",
       "                                ...                        \n",
       "114906    Спала в родительском доме, на своей кровати......\n",
       "114907    RT @jebesilofyt: Эх... Мы немного решили сокра...\n",
       "114908    Что происходит со мной, когда в эфире #proacti...\n",
       "114909    \"Любимая,я подарю тебе эту звезду...\" Имя како...\n",
       "114910    @Ma_che_rie посмотри #непытайтесьпокинутьомск ...\n",
       "Name: ttext, Length: 114911, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_df.ttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Full_df = positive_df.append(negative_df)\n",
    "Full_df = Full_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 226834 entries, 0 to 226833\n",
      "Data columns (total 12 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   id         226834 non-null  int64 \n",
      " 1   tdate      226834 non-null  int64 \n",
      " 2   tmane      226834 non-null  object\n",
      " 3   ttext      226834 non-null  object\n",
      " 4   ttype      226834 non-null  int64 \n",
      " 5   tret       226834 non-null  int64 \n",
      " 6   trep       226834 non-null  int64 \n",
      " 7   tfav       226834 non-null  int64 \n",
      " 8   tstcount   226834 non-null  int64 \n",
      " 9   tfol       226834 non-null  int64 \n",
      " 10  tfrien     226834 non-null  int64 \n",
      " 11  listcount  226834 non-null  int64 \n",
      "dtypes: int64(10), object(2)\n",
      "memory usage: 20.8+ MB\n"
     ]
    }
   ],
   "source": [
    "Full_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нулевых значений нет. Дата представлена в неясном виде, однако, предварительно можно сказать, что для задачи классификации текста она не нужна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tdate</th>\n",
       "      <th>ttype</th>\n",
       "      <th>tret</th>\n",
       "      <th>trep</th>\n",
       "      <th>tfav</th>\n",
       "      <th>tstcount</th>\n",
       "      <th>tfol</th>\n",
       "      <th>tfrien</th>\n",
       "      <th>listcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.268340e+05</td>\n",
       "      <td>2.268340e+05</td>\n",
       "      <td>226834.000000</td>\n",
       "      <td>226834.0</td>\n",
       "      <td>226834.000000</td>\n",
       "      <td>226834.000000</td>\n",
       "      <td>2.268340e+05</td>\n",
       "      <td>2.268340e+05</td>\n",
       "      <td>226834.000000</td>\n",
       "      <td>226834.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.132836e+17</td>\n",
       "      <td>1.387369e+09</td>\n",
       "      <td>0.013173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.118249</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>7.584972e+03</td>\n",
       "      <td>6.770083e+02</td>\n",
       "      <td>332.682746</td>\n",
       "      <td>10.125475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.535456e+15</td>\n",
       "      <td>1.081337e+06</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105.898784</td>\n",
       "      <td>0.035611</td>\n",
       "      <td>2.039972e+04</td>\n",
       "      <td>9.764450e+03</td>\n",
       "      <td>1915.268263</td>\n",
       "      <td>112.100088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.089067e+17</td>\n",
       "      <td>1.386326e+09</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.100277e+17</td>\n",
       "      <td>1.386593e+09</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.730000e+02</td>\n",
       "      <td>2.700000e+01</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.110529e+17</td>\n",
       "      <td>1.386838e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.026000e+03</td>\n",
       "      <td>8.300000e+01</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.157585e+17</td>\n",
       "      <td>1.387960e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.562000e+03</td>\n",
       "      <td>2.570000e+02</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.251386e+17</td>\n",
       "      <td>1.390196e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13817.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.138639e+06</td>\n",
       "      <td>1.582807e+06</td>\n",
       "      <td>388311.000000</td>\n",
       "      <td>16915.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         tdate          ttype      tret           trep  \\\n",
       "count  2.268340e+05  2.268340e+05  226834.000000  226834.0  226834.000000   \n",
       "mean   4.132836e+17  1.387369e+09       0.013173       0.0       3.118249   \n",
       "std    4.535456e+15  1.081337e+06       0.999915       0.0     105.898784   \n",
       "min    4.089067e+17  1.386326e+09      -1.000000       0.0       0.000000   \n",
       "25%    4.100277e+17  1.386593e+09      -1.000000       0.0       0.000000   \n",
       "50%    4.110529e+17  1.386838e+09       1.000000       0.0       0.000000   \n",
       "75%    4.157585e+17  1.387960e+09       1.000000       0.0       0.000000   \n",
       "max    4.251386e+17  1.390196e+09       1.000000       0.0   13817.000000   \n",
       "\n",
       "                tfav      tstcount          tfol         tfrien      listcount  \n",
       "count  226834.000000  2.268340e+05  2.268340e+05  226834.000000  226834.000000  \n",
       "mean        0.001243  7.584972e+03  6.770083e+02     332.682746      10.125475  \n",
       "std         0.035611  2.039972e+04  9.764450e+03    1915.268263     112.100088  \n",
       "min         0.000000  0.000000e+00  0.000000e+00       0.000000       0.000000  \n",
       "25%         0.000000  4.730000e+02  2.700000e+01      29.000000       0.000000  \n",
       "50%         0.000000  2.026000e+03  8.300000e+01      72.000000       0.000000  \n",
       "75%         0.000000  7.562000e+03  2.570000e+02     197.000000       2.000000  \n",
       "max         2.000000  1.138639e+06  1.582807e+06  388311.000000   16915.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Full_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    114911\n",
       "-1    111923\n",
       "Name: ttype, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Full_df.ttype.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значения классов соответсвуют ожиданиям, нет серьезного дисбаланса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=None, char_level=True, oov_token='UNK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataframe = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in positive_df['ttext']:\n",
    "    tokenizer.fit_on_texts(row.lower())\n",
    "    train_dataframe.append((row.lower(), 1))\n",
    "    \n",
    "for row in negative_df['ttext']:\n",
    "    tokenizer.fit_on_texts(row.lower())\n",
    "    train_dataframe.append((row.lower(), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226834"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(train_dataframe, test_size=0.1)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40830"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = \"абвгдеёжзиклмнопрстуфхцчшщъыьэюяabcdefghijklmnopqrstuvwxyz0123456789,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\"\n",
    "char_dict = {}\n",
    "for i, char in enumerate(alphabet):\n",
    "    char_dict[char] = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.word_index = char_dict.copy()\n",
    "tokenizer.word_index[tokenizer.oov_token] = max(char_dict.values()) + 1 # 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame.from_records(train_data)\n",
    "val_df = pd.DataFrame.from_records(val_data)\n",
    "test_df = pd.DataFrame.from_records(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@randa_rin @lovemytommi на компе я к сожалению...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@annamichelekam а как по мне, скучно. ушло вдо...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>поиграла блин с кисой:( http://t.co/ulik1gzi6v</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>зима а у меня бабочка летает по комнате ))) ht...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @wolagasivelu: танчики обновились. патч, сц...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22679</th>\n",
       "      <td>rt @yulia76stimban5: ненавижу болеть( сидеть д...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22680</th>\n",
       "      <td>вот будет классно, если мега пати у нашей пара...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22681</th>\n",
       "      <td>rt @xyhycecixyt: да, на работе у меня тоже yuk...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22682</th>\n",
       "      <td>rt @ediny_marsy: @s_o_o_o_o_n *о* великолепный...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22683</th>\n",
       "      <td>снег... взрослые говорят, что это - замерзшая ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22684 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       0  1\n",
       "0      @randa_rin @lovemytommi на компе я к сожалению...  0\n",
       "1      @annamichelekam а как по мне, скучно. ушло вдо...  0\n",
       "2         поиграла блин с кисой:( http://t.co/ulik1gzi6v  0\n",
       "3      зима а у меня бабочка летает по комнате ))) ht...  1\n",
       "4      rt @wolagasivelu: танчики обновились. патч, сц...  0\n",
       "...                                                  ... ..\n",
       "22679  rt @yulia76stimban5: ненавижу болеть( сидеть д...  0\n",
       "22680  вот будет классно, если мега пати у нашей пара...  0\n",
       "22681  rt @xyhycecixyt: да, на работе у меня тоже yuk...  1\n",
       "22682  rt @ediny_marsy: @s_o_o_o_o_n *о* великолепный...  0\n",
       "22683  снег... взрослые говорят, что это - замерзшая ...  1\n",
       "\n",
       "[22684 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt @mypokunoned: я верю в дружбу между мужчино...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>хочу встретить человека из своего сна ,но я ег...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>всегда мечтал,чтоб на мой день рождения выпал ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#appearancesbsf #interviewbsf /  / все интервь...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sashaiyulskaya хаха, я с радостью отвечу на л...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163315</th>\n",
       "      <td>@nprivaty она ж еще после егэ расклеилась полн...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163316</th>\n",
       "      <td>@ars_rnd @enki_rnd ох, сегодня вряд ли, меня д...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163317</th>\n",
       "      <td>обидно когда ты даешь водителю в маршрутке 5.5...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163318</th>\n",
       "      <td>ого, рой джонс заявил, что хотел бы получить р...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163319</th>\n",
       "      <td>доброе утро! ) какя уже говорила,  с сегодняшн...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163320 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0  1\n",
       "0       rt @mypokunoned: я верю в дружбу между мужчино...  1\n",
       "1       хочу встретить человека из своего сна ,но я ег...  0\n",
       "2       всегда мечтал,чтоб на мой день рождения выпал ...  1\n",
       "3       #appearancesbsf #interviewbsf /  / все интервь...  1\n",
       "4       @sashaiyulskaya хаха, я с радостью отвечу на л...  1\n",
       "...                                                   ... ..\n",
       "163315  @nprivaty она ж еще после егэ расклеилась полн...  0\n",
       "163316  @ars_rnd @enki_rnd ох, сегодня вряд ли, меня д...  0\n",
       "163317  обидно когда ты даешь водителю в маршрутке 5.5...  0\n",
       "163318  ого, рой джонс заявил, что хотел бы получить р...  0\n",
       "163319  доброе утро! ) какя уже говорила,  с сегодняшн...  1\n",
       "\n",
       "[163320 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = train_df[0].values\n",
    "train_texts = [s for s in train_texts]\n",
    "\n",
    "test_texts = test_df[0].values\n",
    "test_texts = [s for s in test_texts]\n",
    "\n",
    "val_texts = val_df[0].values\n",
    "val_texts = [s for s in val_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
    "val_sequences = tokenizer.texts_to_sequences(val_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pad_sequences(train_sequences, maxlen=50, padding = 'post')\n",
    "test_data = pad_sequences(test_sequences, maxlen=50, padding = 'post')\n",
    "val_data = pad_sequences(val_sequences, maxlen=50, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 28, 101,  18, ...,  38,  62,  49],\n",
       "       [  6,  19,  10, ...,  24,  20,  95],\n",
       "       [  3,  15,  19, ...,  74,  91,  96],\n",
       "       ...,\n",
       "       [ 11,   6, 101, ...,  15,  70,  95],\n",
       "       [ 10,   3,  28, ..., 101,  74,  95],\n",
       "       [101,   9,   1, ...,   6,  14,  29]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array(train_data)\n",
    "test_data = np.array(test_data)\n",
    "val_data = np.array(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 28, 101,  18, ...,  38,  62,  49],\n",
       "       [  6,  19,  10, ...,  24,  20,  95],\n",
       "       [  3,  15,  19, ...,  74,  91,  96],\n",
       "       ...,\n",
       "       [ 11,   6, 101, ...,  15,  70,  95],\n",
       "       [ 10,   3,  28, ..., 101,  74,  95],\n",
       "       [101,   9,   1, ...,   6,  14,  29]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes = train_df[1].values\n",
    "train_class_list = [x for x in train_classes]\n",
    "\n",
    "test_classes = test_df[1].values\n",
    "test_class_list = [x for x in test_classes]\n",
    "\n",
    "val_classes = val_df[1].values\n",
    "val_class_list = [x for x in val_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes = to_categorical(train_class_list)\n",
    "test_classes = to_categorical(test_class_list)\n",
    "val_classes = to_categorical(val_class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical(val_class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Параметры модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_weights = []\n",
    "embedding_weights.append(np.zeros(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for char, i in tokenizer.word_index.items():\n",
    "    onehot = np.zeros(vocab_size)\n",
    "    onehot[i - 1] = 1\n",
    "    embedding_weights.append(onehot)\n",
    "embedding_weights = np.array(embedding_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 50\n",
    "vocab_size = 101\n",
    "embedding_size = 101\n",
    "conv_layers = [[256, 7, 3], # 256, 7, 3\n",
    "              ]\n",
    "fully_connected_layers = [384, 384]\n",
    "num_of_classes = 2\n",
    "dropout_p = 0.7\n",
    "optimizer = 'adam'\n",
    "loss = 'binary_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'binary_crossentropy'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(vocab_size+1,\n",
    "                           embedding_size,\n",
    "                           input_length=input_size,\n",
    "                           weights=[embedding_weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Anna.muravyeva\\Anaconda3\\envs\\NewEnvPython37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 50, 101)           10302     \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 44, 256)           181248    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 44, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 14, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3584)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 384)               1376640   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 384)               147840    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 770       \n",
      "=================================================================\n",
      "Total params: 1,716,800\n",
      "Trainable params: 1,716,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(input_size,), name='input', dtype='int64')\n",
    "\n",
    "x = embedding_layer(inputs)\n",
    "\n",
    "for filter_num, filter_size, pooling_size in conv_layers:\n",
    "    x = Conv1D(filter_num, filter_size)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    if pooling_size != -1:\n",
    "        x = MaxPooling1D(pool_size=pooling_size)(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "for dense_size in fully_connected_layers:\n",
    "    x = Dense(dense_size, activation='relu')(x)\n",
    "    x = Dropout(dropout_p)(x)\n",
    "\n",
    "predictions = Dense(num_of_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(train_data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "x_train = train_data[indices]\n",
    "y_train = train_classes[indices]\n",
    "\n",
    "x_test = test_data\n",
    "y_test = test_classes\n",
    "\n",
    "indices = np.arange(train_data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "x_train = train_data[indices]\n",
    "y_train = train_classes[indices]\n",
    "\n",
    "x_test = test_data\n",
    "y_test = test_classes\n",
    "\n",
    "x_val = val_data\n",
    "y_val = val_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights = len(train_dataframe)\n",
    "\n",
    "positive_weight = len(positive_df) / total_weights\n",
    "negative_weight = len(negative_df) / total_weights\n",
    "\n",
    "class_weights = [positive_weight, negative_weight]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5065863142209721, 0.49341368577902783]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Anna.muravyeva\\Anaconda3\\envs\\NewEnvPython37\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\Anna.muravyeva\\Anaconda3\\envs\\NewEnvPython37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 163320 samples, validate on 40830 samples\n",
      "Epoch 1/10\n",
      " - 144s - loss: 0.3448 - accuracy: 0.7966 - val_loss: 0.3216 - val_accuracy: 0.8171\n",
      "Epoch 2/10\n",
      " - 145s - loss: 0.3118 - accuracy: 0.8263 - val_loss: 0.3115 - val_accuracy: 0.8253\n",
      "Epoch 3/10\n",
      " - 145s - loss: 0.3015 - accuracy: 0.8355 - val_loss: 0.3105 - val_accuracy: 0.8280\n",
      "Epoch 4/10\n",
      " - 145s - loss: 0.2944 - accuracy: 0.8422 - val_loss: 0.3104 - val_accuracy: 0.8296\n",
      "Epoch 5/10\n",
      " - 145s - loss: 0.2850 - accuracy: 0.8490 - val_loss: 0.3127 - val_accuracy: 0.8309\n",
      "Epoch 6/10\n",
      " - 145s - loss: 0.2764 - accuracy: 0.8567 - val_loss: 0.3183 - val_accuracy: 0.8306\n",
      "Epoch 7/10\n",
      " - 149s - loss: 0.2688 - accuracy: 0.8621 - val_loss: 0.3136 - val_accuracy: 0.8286\n",
      "Epoch 8/10\n",
      " - 156s - loss: 0.2601 - accuracy: 0.8675 - val_loss: 0.3210 - val_accuracy: 0.8284\n",
      "Epoch 9/10\n",
      " - 149s - loss: 0.2500 - accuracy: 0.8746 - val_loss: 0.3409 - val_accuracy: 0.8309\n",
      "Epoch 10/10\n",
      " - 147s - loss: 0.2432 - accuracy: 0.8804 - val_loss: 0.3354 - val_accuracy: 0.8309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1b58499ccc8>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          validation_data=(x_val, y_val),\n",
    "          #class_weight=class_weights,\n",
    "          batch_size=50,\n",
    "          epochs=10,\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22684/22684 [==============================] - 4s 178us/step\n",
      "[0.32982874726980077, 0.8326132893562317]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.evaluate(x_test, y_test))\n",
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "\n",
    "    text = text.lower()\n",
    "    #print(text)\n",
    "    res = []\n",
    "    for sentence in text.replace('\\n', '. ').split('. '):\n",
    "\n",
    "        tokenized_text = []\n",
    "        tokenized_text.append(sentence)\n",
    "\n",
    "        tokenized_text = tokenizer.texts_to_sequences(tokenized_text)\n",
    "        tokenized_text = pad_sequences(tokenized_text, maxlen=50, padding = 'post')\n",
    "        \n",
    "        #print(model.predict(tokenized_text))\n",
    "        prediction = np.argmax(model.predict(tokenized_text))\n",
    "        if prediction == 0:\n",
    "            pred = 'negativ'\n",
    "        elif prediction == 1:\n",
    "            pred = 'positiv'\n",
    "       \n",
    "        res.append((sentence, pred))\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('я всю ночь пила кофе, смотрела сериалы, прекрасно провела время',\n",
       "  'positiv')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'я всю ночь пила кофе, смотрела сериалы, прекрасно провела время'\n",
    "predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('добрый день! я бы хотел купить автомобиль, зелененький', 'positiv')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Добрый день! Я бы хотел купить автомобиль, зелененький'\n",
    "predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('я бы хотел вернуть автомобиль, он сломался', 'negativ')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Я бы хотел вернуть автомобиль, он сломался'\n",
    "predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('я очень недоволен обслуживанием, вы плохо выполнили свою работу!',\n",
       "  'negativ')]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Я очень недоволен обслуживанием, вы плохо выполнили свою работу!'\n",
    "predict(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
